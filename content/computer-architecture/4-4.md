---
title: Pipelining overview
date: 2022.10.27
slug: 4-4
category: "4. The Processor"
---

Because the longest delay determines clock period, a single-cycle implementation is not used today <br>
It violates **"make the common case fast"**

## Pipelining overview
With the pipelined approach, the speed up can be equal to the number of stages in an ideal case
- A single task is divided into N stages
- Each stage takes teh same amount of time T
- There are M tasks, where M is large enough

To complete all the tasks
- In non-pipelined approach, we need $N \times M \times T$ times
- In pipelined approach, we need $(N + M - 1) \times T \approx M \times T$ time

$$
Time\;between\;tasks_{pipelined} = \frac{Time\;between\;tasks_{non-pipelined}}{Number\;of\;pipeline\;stages}
$$
<br>

### Stage in pipeline
For different stages, different resources are used.
- Stage 1: IF (Fetching an instruction from memory)
- Stage 2: ID (Decoding the instruction and read registers)
- Stage 3: EX (Executing operation or calculating address)
- Stage 4: MEM (Accessing data in data memory)
- Stage 5: wB (Writing the result back into a register)
<br>

### Compared to the single-cycle processor
Compared to the single cycle processor, **clock period in pipelined processor is determined by the longest stage time.**
<center>
<img src="/computer-architecture/4-4/01.jpg"  width="800">
</center>

<br>

$$
Time\;between\;instructions_{pipelined}= the\;longest\;stage\;time \times (the\;number\;of\;instructions + the\;number\;of\;stages - 1)
$$

**If there are a lot of instructions to be executed,**
$$
Time\;between\;instructions_{pipelined} = \frac{Time\;between\;instructions_{non-pipelined}}{\frac{the\;longest\;instruction\;time}{the\;longest\;stage\;time}}
$$
<br>

## Hazards in Pipelining
- Structural hazards
    - When a required resources is busy
- Data hazards
    - When we need to wait for previous instruction to complete its data read/write operation
- Control hazards
    - When we need to make a control decision differently depending on the previous instruction
<br>

### Structural hazards
When a required resource is already used for executing an other instruction
- IF and MEM stages can request to use the same resource at the same time
- it is required to separate instruction / data memories
    - IF and MEM stages use different part of memory (instruction memory, data memory)
<center>
<img src="/computer-architecture/4-4/02.jpg"  width="800">
</center>
<br>

### Data hazards
When an instruction depends on the completion of data access by a previous instruction
<center>
<img src="/computer-architecture/4-4/03.jpg"  width="700">
</center>

Solution: **Forwarding** <br>
Instead of waiting for the target date to be stored in a register,<br>
forward the data as soon as possible with extra connections
<center>
<img src="/computer-architecture/4-4/04.jpg"  width="700">
</center>
<br>

#### Load-use data hazards
But, sometimes, we cannot avoid stalls by forwarding
<center>
<img src="/computer-architecture/4-4/05.jpg"  width="700">
</center>

Solution: **code scheduling**<br>
Reorder code to avoid the load-use data hazards (done by compiler)
<center>
    <img src="/computer-architecture/4-4/06.jpg"  width="700">
    before code scheduling 
</center>
<br>
<center>
    <img src="/computer-architecture/4-4/07.jpg"  width="700">
    after code scheduling
</center>

<br>

### Control hazards
Hazards with branch instructions <br>
We should wait until branch outcome is determined before fetching the next instruction
<center>
    <img src="/computer-architecture/4-4/08.jpg"  width="700">
</center>

Solution: **Compare registers and compute target early in the pipeline**
- Especially, by adding hardware to do it in **ID stage**
- But, still there is **one** pipeline bubble
<center>
    <img src="/computer-architecture/4-4/09.jpg"  width="700">
</center>

Solution: **branch prediction**
With additional HW for early comparison and computation in ID stage
- just fetch instruction with no bubble
    - if prediction correct: keep going
    - if prediction incorrect: cancel the process & add bubble
<br>

## Summary
**Pipelining improves performance by increasing instruction throughput**
- Executes multiple instructions in parallel
- The execution time of each instruction is not affected

**Pipeline hazards**
- Structural hazards
    - Solution: separate data / instruction memories
- (Load-use) Data hazards
    - Solution: forwarding + code scheduling
- Control hazards
    - Solution: early comparison & computation + branch prediction